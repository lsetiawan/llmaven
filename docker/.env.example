# LLMaven Environment Configuration

# Postgres
POSTGRES_HOST=${POSTGRES_HOST:-db}
POSTGRES_DB=llmaven
POSTGRES_USER=llmaven-admin
POSTGRES_PASSWORD=dbpassword9090
POSTGRES_PORT=5432

# MinIO
MINIO_HOST=${MINIO_HOST:-minio}
MINIO_PORT=9000
MINIO_ROOT_USER=${AWS_ACCESS_KEY_ID:-minioadmin}
MINIO_ROOT_PASSWORD=${AWS_SECRET_ACCESS_KEY:-minioadmin}
S3_ENDPOINT_URL=http://${MINIO_HOST}:${MINIO_PORT}

# MLflow
MLFLOW_HOST=${MLFLOW_HOST:-mlflow}
MLFLOW_PORT=8080
MLFLOW_BACKEND_STORE_URI=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/mlflow_db

## S3/MinIO settings
MLFLOW_DEFAULT_ARTIFACT_ROOT=s3://mlflow/
MLFLOW_S3_ENDPOINT_URL=${S3_ENDPOINT_URL}
AWS_ACCESS_KEY_ID=${MINIO_ROOT_USER}
AWS_SECRET_ACCESS_KEY=${MINIO_ROOT_PASSWORD}
MLFLOW_S3_IGNORE_TLS="true"


# LiteLLM
LITELLM_DB=litellm_db
LITELLM_DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/litellm_db
DATABASE_URL=${LITELLM_DATABASE_URL}
MLFLOW_TRACKING_URI=http://${MLFLOW_HOST}:${MLFLOW_PORT}
MLFLOW_EXPERIMENT_NAME="Default"
## Master Key for LiteLLM Proxy (set this to secure your proxy)
LITELLM_MASTER_KEY=sk-1234

# API Keys for various LLM providers
# Add the keys for the providers you want to use

# OpenAI
# OPENAI_API_KEY=your-openai-api-key

# Anthropic
# ANTHROPIC_API_KEY=your-anthropic-api-key

# Azure OpenAI (Required for config.yaml)
AZURE_API_KEY=your-azure-api-key
AZURE_API_BASE=https://your-resource.openai.azure.com/
AZURE_API_VERSION=2024-12-01-preview
